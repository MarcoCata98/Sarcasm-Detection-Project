{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f75399d",
   "metadata": {},
   "source": [
    "# Sarcasm-Detection-Project\n",
    "## Definizione di IRONIA\n",
    "L‚Äôironia √® una figura retorica che esprime il contrario del significato letterale, suggerendo intenzionalmente un significato secondario o implicito.\n",
    "L'ambiguit√† dell ironia √® completamente lessicale, questo la rende molto difficile da per sistemi informatici che operano solo sulla grammatica di un testo.\n",
    "\n",
    "Il termine Ironia e sinonimo di sarcasmo satira e parodia in base al contesto, che appunto determina quanto sia realistica la cosa appena detta.\n",
    "Alcuni testi, definiscono il sarcasmo come un ironia pi√π fredda e tagliente allo scopo di deridere e offendere, per questo progetto tratteremo in modo uguale entrambi i termini.\n",
    "\n",
    "E quindi l'obbiettivo del progetto √® definire un classificatore binario , dato in input un testo , ritorna un valore da 0 a 1 , 0 = classe negativa => non ironico,  1 = classe positiva => ironico\n",
    "\n",
    "## Che cos‚Äô√® (e che cosa non √®) l‚Äôironia\n",
    "\n",
    "Nel linguaggio comune spesso si distingue tra **ironia** e **sarcasmo**.  \n",
    "In questo lavoro non facciamo una separazione netta: consideriamo **ironia** tutto ci√≤ che gioca sul dire una cosa per intenderne un‚Äôaltra (incluso il sarcasmo).\n",
    "\n",
    "### Regola di base\n",
    "\n",
    "L‚Äôironia (e in particolare il sarcasmo) si basa su una regola fondamentale:\n",
    "\n",
    "> **Dire A per intendere non-A.**  \n",
    "> Deve esserci una **forte contraddizione** con il contesto.\n",
    "\n",
    "La vera difficolt√† per la rete sar√† proprio questa:  \n",
    "**ricostruire il contesto e la contraddizione a partire da poche parole della frase.**\n",
    "\n",
    "Esempi:\n",
    "\n",
    "- ‚ÄúChe bella idea perdere l‚Äôautobus!‚Äù ‚Üí in realt√† significa che √® stata una pessima idea.  \n",
    "- ‚ÄúBravo, continua cos√¨‚Ä¶‚Äù (in un contesto negativo) ‚Üí non √® un complimento, ma una critica ironica.\n",
    "\n",
    "### Quando NON c‚Äô√® ironia\n",
    "\n",
    "Esempio:\n",
    "\n",
    "> ‚ÄúIl tramonto a Odaiba oggi era qualcosa di incredibile, sembrava un film.‚Äù\n",
    "\n",
    "- üåÖ ‚ÄúIl tramonto era incredibile‚Äù ‚Üí significa davvero che il tramonto era incredibile.  \n",
    "- üé¨ ‚ÄúSembrava un film‚Äù ‚Üí sottolinea che era molto scenografico.\n",
    "\n",
    "Qui **non c‚Äô√® contraddizione**, √® solo una metafora: il parlante dice esattamente ci√≤ che pensa.  \n",
    "Per parlare di ironia, invece, **deve esserci contraddizione** tra le parole e la situazione.\n",
    "\n",
    "---\n",
    "\n",
    "## Indicatori di ironia (che il modello pu√≤ davvero imparare)\n",
    "\n",
    "Alcuni segnali che possono aiutare il modello a riconoscere l‚Äôironia:\n",
    "\n",
    "- **Contraddizione logica o di contesto**  \n",
    "  > ‚ÄúMi sa che il pesce luna ha pi√π voglia di lavorare di me oggi.‚Äù\n",
    "\n",
    "- **Esagerazione assurda e non letterale**  \n",
    "  > ‚ÄúQuesto pesce √® cos√¨ lento che potrebbe partecipare a una maratona per lumache.‚Äù\n",
    "\n",
    "- **Finta ammirazione / finto entusiasmo**  \n",
    "  > ‚ÄúS√¨ certo, il polpo voleva proprio conoscermi, l‚Äôho visto negli occhi.‚Äù\n",
    "\n",
    "- **Attribuzione di intenzioni assurde agli animali (o ad oggetti)**  \n",
    "  > ‚ÄúIl pesce palla si √® gonfiato‚Ä¶ sicuramente solo per impressionarmi, che romantico.‚Äù\n",
    "\n",
    "- **Gioco di parole sarcastico**  \n",
    "  > ‚ÄúQuesti piranha sembrano molto accoglienti, quasi‚Ä¶ troppo.‚Äù\n",
    "\n",
    "- **Ridicolizzazione implicita**  \n",
    "  > ‚ÄúIl granchio mi ha salutato‚Ä¶ o forse stava solo chiedendo di andarmene.‚Äù\n",
    "(quindi spesso legato allo scherzo, e al prendere in giro, in modo simpatico o per offesa)\n",
    "---\n",
    "\n",
    "## Che cosa NON √® ironia\n",
    "\n",
    "Ci sono espressioni o metafore molto colorite o colloquiali che **non sono ironiche**, anche se contengono metafore o iperboli e spesso finiscono nel linguaggio dei social. Ad esempio:\n",
    "\n",
    "- ‚ÄúIl sole oggi spacca, giornata perfetta per sciare.‚Äù ‚Üí qui ‚Äúspacca‚Äù √® solo un modo di dire positivo.  \n",
    "- ‚ÄúRaga giuro, le foto in cima sono venute una bomba.‚Äù ‚Üí ‚Äúuna bomba‚Äù indica che le foto sono venute molto bene.\n",
    "\n",
    "In questi casi **non c‚Äô√® contraddizione**,  tra quello che viene detto e quello che si intende:  \n",
    "la frase esprime esattamente un giudizio positivo, quindi nel dataset sar√† etichettata come **non ironica (0)**.\n",
    "\n",
    "Mentre se la frase fosse \"la tensione si taglia con il coltello\" √® un modo di dire ironico,\n",
    "!! TROVARE GRAMMATICALMENTE LA DIFFERENZA TRA QUESTE 2\n",
    "\n",
    "## Primo dataset: IronITA\n",
    "Il primo dataset utilizzato si chiama IronITA, proviene dal universit√† di Torino, ed √® stato creato per l'evento EVALITA 2018 (13 dicembre 2018), ideato per scoprire nuovi strumenti di Natural Processing e Speech.\n",
    "(Articolo estratto dal evento https://ceur-ws.org/Vol-2263/paper005.pdf, autori: Cignarella,Frenda,Basile,Bosco,Patti,Rosso).\n",
    "\n",
    "Il dataset contiene 3,977 tweets scelti con distribuzione uniforme dalla community di twitter italiana.\n",
    "per ogni frase registrata, vengono indicati 2 valori, ironia o sarcasmo o la mancanza di entrambi.\n",
    "(Dato che li abbiamo unificati, consideriamo 1 presenza di una dei 2 tipi di ironia , 0 l'assenza di entrambi)\n",
    "\n",
    "Il dataset √® molto realistico ed estratto da conversazioni reali, ma troppo legate a temi specifici (politici del 2018)...\n",
    "\n",
    "## Secondo dataset\n",
    "Per questo motivo ho scritto personalmente un dataset pi√π generale, facendo 4000 frasi di esempio riguardo frasi ironiche e non ironiche (divise 50/50) basandomi sulle regole fissate.\n",
    "\n",
    "Esempio\n",
    "\n",
    "1296,\"Mi sono affezionato a un personaggio secondario‚Ä¶ errore da principiante.\",0\n",
    "1297,\"La nuova stagione √® talmente piena di colpi di scena che ho controllato se fosse uno scherzo della produzione.\",1\n",
    "\n",
    "\n",
    "--\n",
    "\n",
    "# Transformer\n",
    "\n",
    "Il **Transformer** √® l‚Äôarchitettura oggi pi√π utilizzata quando si vuole comprendere la **semantica** di un testo in linguaggio naturale.  \n",
    "√à stato introdotto da un gruppo di ricercatori di Google nel paper:\n",
    "\n",
    "**‚ÄúAttention Is All You Need‚Äù (Vaswani et al., 2017)**  \n",
    "https://arxiv.org/abs/1706.03762\n",
    "\n",
    "La sua caratteristica principale √® che **non legge la frase parola per parola**, come facevano le reti RNN/LSTM, ma elabora **tutto il testo in parallelo**.  \n",
    "Grazie al meccanismo di **self-attention**, il modello decide quanta importanza dare a ciascuna parola in base al contesto generale.\n",
    "\n",
    "### Esempio\n",
    "Frase ironica:\n",
    "> ‚ÄúChe bella idea perdere l‚Äôautobus!‚Äù\n",
    "\n",
    "Il modello pu√≤ capire che:\n",
    "- ‚Äúbella idea‚Äù √® solitamente un‚Äôespressione positiva,\n",
    "- ‚Äúperdere l‚Äôautobus‚Äù √® un evento negativo,\n",
    "- la combinazione produce una **contraddizione** ‚Üí possibile ironia.\n",
    "\n",
    "I modelli sequenziali tradizionali non potevano cogliere bene queste relazioni, perch√© analizzavano ogni parola in modo troppo indipendente dal resto della frase.\n",
    "\n",
    "---\n",
    "\n",
    "# Applicazioni del Transformer\n",
    "\n",
    "Il Transformer √® estremamente modulare e pu√≤ essere adattato a molti task, tra cui:\n",
    "\n",
    "- classificazione\n",
    "- sentiment analysis\n",
    "- irony detection\n",
    "- traduzione automatica\n",
    "- generazione di testo\n",
    "- riassunto\n",
    "- question answering  \n",
    "- e molto altro\n",
    "\n",
    "---\n",
    "\n",
    "# Struttura di un Transformer\n",
    "\n",
    "Un Transformer √® composto da vari blocchi ripetuti chiamati **Encoder Layers**.  \n",
    "Ogni Encoder contiene i seguenti componenti:\n",
    "\n",
    "### üîπ 1. Embedding\n",
    "Trasforma ogni parola in un vettore numerico di **dimensione fissa**.\n",
    "\n",
    "### üîπ 2. Positional Encoding\n",
    "Il Transformer non ha un ordine ‚Äúnaturale‚Äù, quindi √® necessario aggiungere informazioni sulla **posizione** delle parole nella frase.\n",
    "\n",
    "### üîπ 3. Multi-Head Self-Attention\n",
    "Il cuore del modello.  \n",
    "Per ogni parola valuta:\n",
    "- quali altre parole sono importanti,\n",
    "- quali relazioni semantiche esistono,\n",
    "- come collegare i concetti.\n",
    "\n",
    "Permette di comprendere l‚Äôintero contesto.\n",
    "\n",
    "### üîπ 4. Add & Layer Normalization\n",
    "Blocchi di stabilizzazione che migliorano l‚Äôapprendimento.\n",
    "\n",
    "### üîπ 5. Feed-Forward Network\n",
    "Una piccola rete neurale applicata a ogni token, che rifinisce e trasforma le informazioni raccolte dall‚Äôattenzione.\n",
    "\n",
    "\n",
    "\n",
    "# Quanti layer servono?\n",
    "\n",
    "Un Transformer completo pu√≤ usare da **1 fino a 48 encoder layers** (es. GPT-3).  \n",
    "Nel nostro progetto useremo un **mini-Transformer locale**, quindi **1 o 2 layer** sono sufficienti per il dataset di irony detection.\n",
    "\n",
    "\n",
    "# BERT\n",
    "\n",
    "**BERT** (*Bidirectional Encoder Representations from Transformers*) √® un modello di Google (2018) basato **solo sugli encoder**.  \n",
    "√à pre-addestrato su enormi quantit√† di testo con hardware molto potente, ed √® diventato uno standard nelle applicazioni NLP.\n",
    "\n",
    "La maggior parte dei progetti reali parte da BERT gi√† addestrato.\n",
    "\n",
    "Nel mio caso, invece, ho scelto di **costruire il modello da zero**, sia per motivi didattici che per capire nel dettaglio come funziona l‚Äôapprendimento dell‚Äôironia.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# Rioridinamento pulizia del dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
